# 금융 데이터에 대한 간단한 모델 개발 실습
app.py
```python
# -*- coding: utf-8 -*-
"""Day5_실습.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DTkq-a_F6lKzzpW5MiFcJNp-50NG2JoJ
"""

# 필요한 라이브러리 임포트
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# 랜덤 데이터 생성
np.random.seed(42)

n = 1000

data = {
    'customer_id': np.arange(1, n+1),
    'age': np.random.randint(18, 70, size=n),
    'tenure': np.random.randint(1, 10, size=n),
    'balance': np.random.uniform(0, 25000, size=n),
    'num_products': np.random.randint(1, 4, size=n),
    'has_credit_card': np.random.choice([0,1], size=n),
    'is_active_member': np.random.choice([0,1], size=n),
    'estimated_salary': np.random.uniform(30000, 150000, size=n),
    'churn': np.random.choice([0,1], size=n, p=[0.8,0.2])
}

# data frame
df = pd.DataFrame(data)
# save as csv
df.to_csv('customer_churn_data.csv', index=False)
# data
df.head()

df.info()

"""# 데이터 로딩"""

import sklearn.model_selection
import sklearn.preprocessing
import sklearn.metrics

data = pd.read_csv('customer_churn_data.csv')

# 데이터 확인
print(data.head())

# 결측값 확인
print(data.isna().sum())

"""# 전처리"""

# 특징 및 라벨 분리
X = data.drop('churn', axis=1)
y = data['churn']

# 범주형 변수 처리 - One-Hot Encoding
# categorical_cols = ['num_products', 'has_credit_card', 'is_active_member']
# X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

# 데이터 분할
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=42)

# 데이터 표준화
# 계량형 - StandardScaler, 분류형 - MinMaxScaler
scaler = sklearn.preprocessing.MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

plt.boxplot(X_train)

"""# Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# train model
model = LogisticRegression()
model.fit(X_train, y_train)

# predict
y_pred = model.predict(X_test)

# evaluate
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# train model
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

# predict
rf_pred = rf_model.predict(X_test)

# evaluate
print("Accuracy:", accuracy_score(y_test, rf_pred))
print("Classification Report:\n", classification_report(y_test, rf_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, rf_pred))

"""# Performance"""

# visualize confusion matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Accuracy, Recall, F1-score
print(classification_report(y_test, y_pred))

"""# Hyperparameter Tuning"""

from sklearn.model_selection import GridSearchCV

# Hyperparameter Grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

# Random Forest Model Tuning
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Best Parameters
print("Best Parameters:", grid_search.best_params_)

# Best Model
best_rf_model = grid_search.best_estimator_
y_pred_tuned = best_rf_model.predict(X_test)

# Evaluate Tuned Model
print("Tuned Accuracy:", accuracy_score(y_test, y_pred_tuned))

import joblib

# save model
joblib.dump(best_rf_model, 'best_rf_model.pkl')

# predict model
loaded_model = joblib.load('best_rf_model.pkl')
new_pred = loaded_model.predict(X_test)
print(f'Predicted Churn: {new_pred[0]}')
print("Accuracy:", accuracy_score(y_test, new_pred))



"""# Streamlit"""

!pip install streamlit

import streamlit as st
import pandas as pd

st.title('Customer Churn Prediction')
st.subheader('Upload Data')
uploaded_file = st.file_uploader("Choose a file", type="csv")
if uploaded_file is not None:
    data = pd.read_csv(uploaded_file)
    st.write(data.head())

```
